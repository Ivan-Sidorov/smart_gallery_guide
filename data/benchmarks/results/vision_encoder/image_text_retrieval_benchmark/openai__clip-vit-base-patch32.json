{
  "meta": {
    "model": "openai/clip-vit-base-patch32",
    "batch_size": 64,
    "benchmark": "/workspace/smart_gallery_guide/data/benchmarks/image_text_retrieval_benchmark.jsonl",
    "task": "text->image",
    "n_docs": 100,
    "n_queries": 100,
    "encode_seconds_total": 0.5363445281982422,
    "backend": "faiss"
  },
  "overall": {
    "n": 100,
    "mrr@5": 0.05316666666666667,
    "map@1": 0.03,
    "map@5": 0.05316666666666667
  }
}